name: Daily Scraper

on:
  schedule:
    - cron: "0 0 * * *" # This runs the job daily at midnight
  workflow_dispatch: # Allows manual trigger

jobs:
  run_daily_scraper:
    runs-on: self-hosted

    steps:
      # - name: Checkout repository
      #   uses: actions/checkout@v2

      # - name: Set up Python
      #   uses: actions/setup-python@v2
      #   with:
      #     python-version: "3.11.9"

      - name: Install dependencies
        run: |
          source /home/milky/Envs/n1_scraper/bin/activate
          pip install -r /home/milky/N1Scraper/requirements.txt

      - name: Create data directories
        run: |
          mkdir -p /home/milky/N1Scraper/data_temp

      - name: Run scraper script
        run: python /home/milky/N1Scraper/scraper/n1_scraper.py

      - name: Echo job status
        run: echo "Daily scraper job status is ${{ job.status }}."

      - name: Push to GH
        run: | 
          cd /home/milky/N1Scraper/
          git config url."https://oauth2:${{ secrets.GH_TOKEN }}@github.com".insteadOf https://github.com
          git add data/articles.db data/last_scraped_datetime.txt data/duplicates.json 
          git commit -m "data_update"
          git push origin main
  
